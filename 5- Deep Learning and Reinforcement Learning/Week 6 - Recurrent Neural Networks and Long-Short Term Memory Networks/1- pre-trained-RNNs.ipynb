{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceabdfa5-46ee-41b3-b624-0d45d2d56675",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02574b-53ff-4cbd-9264-8c6932a928bd",
   "metadata": {},
   "source": [
    "# **Recurrent Neural Networks**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545db63-0ae3-44c5-8bcc-cc843ce099fe",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n",
    "\n",
    "A recurrent neural network (RNN) is a type of artificial neural network which uses sequential data or time series data as input. Its typically used for ordinal or temporal problems like language translation, speech recognition, and time series forecasting. \n",
    "\n",
    "In this lab, we will understand the fundamental building blocks of an RNN. We will train a simple binary text classifier on top of an existing pre-trained module that embeds sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32467c3c-7080-45ca-93b2-dd6fa4cca1b2",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#RNN-Fundamentals\">RNN Fundamentals</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Vanilla-Recurrent-Neural-Network\"> Vanilla Recurrent Neural Network</a></li>\n",
    "            <li><a href=\"#Unrolling-in-time-of-a-RNN\">Unrolling in time of a RNN</a></li>\n",
    "            <li><a href=\"#Training-an-RNN\">Training an RNN</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Types-of-RNNs\">Types of RNNs</a></li>\n",
    "    <li><a href=\"#Pre-trained-RNNs\">Pre-trained RNNs</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa8ef1-5e18-40ee-99ce-ab622b8620fa",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    " - Describe the fundamental building blocks of RNNs.\n",
    " - Implement pre-trained RNNs to solve time-series prediction, and forecasting, and text classification tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc0cd0-37a4-493b-9b82-9dcd3903de65",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28631fff-2635-4838-aa2f-9e702c82bc51",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e873e7-45e8-4bce-acf5-7a978178f5cc",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764935b6-665e-4175-a512-7ba3e0e0c4f3",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run these notebook commands in a different Jupyter environment (like Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22609f3-525a-4a56-a450-54c852cce0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "# !mamba install -qy pandas numpy seaborn matplotlib scikit-learn\n",
    "# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fd032-8fe7-4a7a-a9f8-69444a0b41bd",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed95664-21fc-4793-a49d-b3bb4d4bc237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow_hub\n",
    "!pip install tensorflow --upgrade\n",
    "!mamba install -qy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b711e10d-ec44-48cb-b35f-d0a63bc4ade8",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eaee927-895f-4fb1-900d-30fdc8aa7391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 23:10:26.363186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-17 23:10:26.494098: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-17 23:10:26.498857: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-17 23:10:26.498886: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-17 23:10:27.296620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-17 23:10:27.296817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-17 23:10:27.296838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf. __version__)\n",
    "import skillsnetwork\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Masking,LSTM, GRU, Conv1D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SimpleRNN\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "np.random.seed(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c057cc-32a4-4c85-8462-3e391dcd86ce",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a05cb5-eafb-4096-8778-02123df6504b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to compute the accuracy, precision, recall and F1 score of a model's predictions.\n",
    "def calculate_results(y_true, y_pred):\n",
    "    model_accuracy = accuracy_score(y_true, y_pred)\n",
    "    model_precision, model_recall, model_f1,_ = precision_recall_fscore_support(y_true, y_pred,average=\"weighted\")\n",
    "    model_results = {\"accuracy\":model_accuracy,\n",
    "                     \"precision\":model_precision,\n",
    "                     \"recall\" :model_recall,\n",
    "                     \"f1\":model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e4f95a-a59e-43d9-8363-56c3b9ea5e2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RNN Fundamentals\n",
    "\n",
    "RNNs fall in the category of neural networks that maintain some kind of **state**. They can process sequential data of arbitrary length. By doing so, they overcome certain limitations faced by classical neural networks. Classical NNs only accept fixed-length vectors as input and output fixed-length vectors. RNNs operate over sequences of vectors. Classical NNs aren't built to consider the sequential nature of some data. RNNs work with sequential data forms like language, video frames, time series, and so on.\n",
    "\n",
    "The RNN layer uses a for-loop to iterate over the time-steps of a sequence, and maintains an internal state that encodes information about all time-steps that have been observed so far. The Keras RNN API has built-in `keras.layers.RNN` and `keras.layers.LSTM` layers that make it easy to quickly build RNN models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d46976-6f1c-48ee-bbdd-ba3ee0ebc3c3",
   "metadata": {},
   "source": [
    "### Vanilla Recurrent Neural Network\n",
    "\n",
    "RNNs use these two simple formulas:\n",
    "\n",
    "$$ \\mathbf s_t = \\mbox{tanh }(U \\mathbf x_t + W \\mathbf s_{t-1}) $$\n",
    "\n",
    "$$ \\mathbf y_t = V \\mathbf s_t $$ \n",
    "\n",
    "The following plot shows the hyperbolic tan function, `tanh`:\n",
    "\n",
    "<img src=\"https://github.com/DataScienceUB/DeepLearningMaster2019/blob/master/images/TanhReal.gif?raw=1\" alt=\"\" style=\"width: 300px;\">\n",
    "\n",
    "#### Terminology:\n",
    "* $s_t$ current network, or the hidden state\n",
    "* $\\mathbf s_{t-1}$ previous hidden state\n",
    "* $\\mathbf x_t$ current input\n",
    "* $U, V, W$ matrices that are parameters of the RNN\n",
    "* $\\mathbf y_t$ output at time $t$\n",
    "\n",
    "These equations say that the current network state or the hidden state, is a function of the previous hidden state and the current input. \n",
    "\n",
    "### Unrolling in time of a RNN\n",
    "\n",
    "Given an input sequence, we apply RNN formulas in a recurrent way until we process all input elements. The $U,V,W$ parameters are shared across all recurrent steps. This implies that at each time step, the output is a function of all inputs from previous time steps. The network has a form of memory, encoding information about the time-steps it has seen so far.\n",
    "\n",
    "Some important observations:\n",
    "- The initial values for $U,V,W$ as well as for $\\mathbf s$ must be provided when training an RNN.\n",
    "- Hidden state  acts as a memory of the network. It can capture information about the previous steps. It embeds the representation of the sequence.\n",
    "- We can look at the network's output at every stage or just the final stage.\n",
    "\n",
    "### Training an RNN\n",
    "\n",
    "A RNN has a layer for each time step, and its weights are shared across time. It is trained using backpropagation through time, and is done using the following steps:\n",
    "- The input or the training set is made of several input ($n$-dimensional) sequences $\\{\\mathbf{X}_i \\}$ and corresponding outcomes. Each element of a sequence $\\mathbf{x}_j \\in \\mathbf{X}_i$ is also a vector.\n",
    "- We use a loss function to measure how well the network's output fits to the expected outcome, such as ground truth.\n",
    "- We apply an optimization method like stochastic gradient descent or Adam to optimize the loss function\n",
    "- After the forward pass, gradients of the cost function are propagated backwards through the unrolled network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa5f19-ceea-43bd-876c-32e9a8909be1",
   "metadata": {},
   "source": [
    "## Types of RNNs\n",
    "\n",
    "Predicting the output, $y_t$, at each time step is not always the case. Different RNN architectures can be used to solve different kinds of problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869ab6e-db77-403b-8755-011eeb0e116e",
   "metadata": {},
   "source": [
    "|Type|Input|Output|Example problem\n",
    "|-|-|-|-\n",
    "|*many-to-many*|An input sequence|An output sequence|Part of Speech (POS) tagging\n",
    "|*many-to-one*|An input sequence|Value of output sequence for last timestep|Text classification: positive tweet or negative?\n",
    "|*one-to-many*|Single value of input sequence|An output sequence| Given an input image, predict sequence data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fc57f-19f8-4076-aa2b-a13bb3f56675",
   "metadata": {},
   "source": [
    "## Pre-trained RNNs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499aaba-6a3c-4933-96fc-881ba3c3d401",
   "metadata": {},
   "source": [
    "In this section, we will be experimenting with existing RNNs. We will use the NLP disaster dataset. The dataset contains a `test.csv` and a `train.csv` each of which have the following information:\n",
    "\n",
    "* The text of a tweet\n",
    "* A keyword from that tweet (although this may be blank!)\n",
    "* The location the tweet was sent from (may also be blank)\n",
    "\n",
    "Our task is to predict whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2457c40-04ea-4d4f-acc8-527f947e428d",
   "metadata": {},
   "source": [
    "Let us start by downloading and unzipping the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b8c05f-0165-4ceb-bdd1-9349525dd737",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1069e41be741a6aaedd97ada400255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading nlp_disaster.zip:   0%|          | 0/607343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a4b76ac0cf4f8aa122a881935b99fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to '.'\n"
     ]
    }
   ],
   "source": [
    "await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module4/L1/nlp_disaster.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53138509-46b3-417a-b861-c312e73bf0b6",
   "metadata": {},
   "source": [
    "Now we will read in the train dataset. Here we use `frac=1` so all rows in the training dataset are returned in a random order. We also set a random state to ensure reproducibility of results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2642e5d-631b-494a-9cc3-ae8247104ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "# shuffle the dataset \n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8cee2c-5ef4-482f-8c8e-dbaad8d026d9",
   "metadata": {},
   "source": [
    "We will use 90% of the entire labelled dataset for training, and 10% of it for testing purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e0a9d5-554c-476f-ab54-cfeff7b352ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6851,), (6851,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into 90% training and 10% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                    train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                    test_size = 0.1,\n",
    "                                                    random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72599f3-17fc-4e43-b2d2-be73c93595a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9bed73-1fb5-4f47-b964-1b5a133eceea",
   "metadata": {},
   "source": [
    "`TextVectorization` is a preprocessing layer which maps text features to integer sequences. We also specify `lower_and_strip_punctuation` as the standardization method to apply to the input text. The text will be lowercased and all punctuation removed. Next we split on the whitespace, and pass `None` to `ngrams` so no ngrams are created.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463f67bb-31fc-44d5-9f69-68f705e7b45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 23:28:16.876532: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-17 23:28:16.876604: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-17 23:28:16.876648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyterlab-ahmadking31j): /proc/driver/nvidia/version does not exist\n",
      "2023-05-17 23:28:16.877340: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=None, \n",
    "                                    #remove punctuation and make letters lowercase\n",
    "                                    standardize=\"lower_and_strip_punctuation\", \n",
    "                                    #whitespace delimiter\n",
    "                                    split=\"whitespace\", \n",
    "                                    #dont group anything, every token alone\n",
    "                                    ngrams = None, \n",
    "                                    output_mode =\"int\",\n",
    "                                    #length of each sentence == length of largest sentence\n",
    "                                    output_sequence_length=None\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44018c57-ff84-490c-9d5a-5cf3a229bb88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "\n",
    "# number of words in the vocabulary \n",
    "max_vocab_length = 10000\n",
    "# tweet average length\n",
    "max_length = 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e1042-2608-4901-bc22-0d0f001216cd",
   "metadata": {},
   "source": [
    "Below we define an `Embedding` layer with a vocabulary of 10,000, a vector space of 128 dimensions in which words will be embedded, and input documents that have 15 words each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c280fb00-c208-4091-9fec-e1d70ae2eaae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim= max_vocab_length,\n",
    "                             output_dim=128,\n",
    "                             input_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171967c-5beb-4af4-97d6-dbb09db34952",
   "metadata": {},
   "source": [
    "The `hub.KerasLayer` wraps a SavedModel (or a legacy TF1 Hub format) as a Keras Layer. The `universal-sentence-encoder` is an encoder of greater-than-word length text trained on a variety of data. It can be used for text classification, semantic similarity, clustering, and other natural language tasks. \n",
    "\n",
    "> We can train a simple binary text classifier on top of any TF-Hub module that can embed sentences. The Universal Sentence Encoder was partially trained with custom text classification tasks in mind. These kinds of classifiers can be trained to perform a wide variety of classification tasks often with a very small amount of labeled examples.\n",
    "\n",
    "More on this is found in the Tensorflow Hub [documentation](https://tfhub.dev/google/universal-sentence-encoder/4?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera747-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ada2b2-1351-4322-bb29-000d4cf892fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                               input_shape=[],\n",
    "                               dtype = tf.string,\n",
    "                               trainable=False,\n",
    "                               name=\"pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45968087-0dc6-4b00-a346-f35a54cd063c",
   "metadata": {},
   "source": [
    "The `encoder_layer` will take as input variable length English text and the output is a 512 dimensional vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b4333-fa87-4db3-aa5d-b1f723a6aa2f",
   "metadata": {},
   "source": [
    "We will add a Dense layer with unit 1 to create a simple binary text classifier on top of any TF-Hub module. Next, we will compile and fit it using 20 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a63a7ea-feb9-4b7c-acef-abe94d8d8f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 [==============================] - 8s 22ms/step - loss: 0.6518 - accuracy: 0.7288 - val_loss: 0.6146 - val_accuracy: 0.7769\n",
      "Epoch 2/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.5839 - accuracy: 0.7895 - val_loss: 0.5639 - val_accuracy: 0.7848\n",
      "Epoch 3/20\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.5401 - accuracy: 0.7933 - val_loss: 0.5312 - val_accuracy: 0.7900\n",
      "Epoch 4/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.5110 - accuracy: 0.7990 - val_loss: 0.5096 - val_accuracy: 0.7913\n",
      "Epoch 5/20\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.4905 - accuracy: 0.7981 - val_loss: 0.4949 - val_accuracy: 0.7913\n",
      "Epoch 6/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4756 - accuracy: 0.8003 - val_loss: 0.4843 - val_accuracy: 0.7940\n",
      "Epoch 7/20\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.4643 - accuracy: 0.8024 - val_loss: 0.4766 - val_accuracy: 0.7953\n",
      "Epoch 8/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4554 - accuracy: 0.8035 - val_loss: 0.4705 - val_accuracy: 0.7979\n",
      "Epoch 9/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4484 - accuracy: 0.8057 - val_loss: 0.4660 - val_accuracy: 0.7979\n",
      "Epoch 10/20\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.4426 - accuracy: 0.8081 - val_loss: 0.4627 - val_accuracy: 0.7979\n",
      "Epoch 11/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4378 - accuracy: 0.8089 - val_loss: 0.4597 - val_accuracy: 0.7953\n",
      "Epoch 12/20\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.4339 - accuracy: 0.8097 - val_loss: 0.4574 - val_accuracy: 0.7966\n",
      "Epoch 13/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4303 - accuracy: 0.8114 - val_loss: 0.4557 - val_accuracy: 0.7979\n",
      "Epoch 14/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4273 - accuracy: 0.8116 - val_loss: 0.4540 - val_accuracy: 0.8018\n",
      "Epoch 15/20\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.4246 - accuracy: 0.8127 - val_loss: 0.4527 - val_accuracy: 0.8018\n",
      "Epoch 16/20\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.4224 - accuracy: 0.8140 - val_loss: 0.4517 - val_accuracy: 0.8045\n",
      "Epoch 17/20\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.4203 - accuracy: 0.8149 - val_loss: 0.4508 - val_accuracy: 0.8058\n",
      "Epoch 18/20\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.4185 - accuracy: 0.8161 - val_loss: 0.4499 - val_accuracy: 0.8058\n",
      "Epoch 19/20\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.4168 - accuracy: 0.8164 - val_loss: 0.4493 - val_accuracy: 0.8058\n",
      "Epoch 20/20\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4153 - accuracy: 0.8171 - val_loss: 0.4484 - val_accuracy: 0.8071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85e82374d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             encoder_layer,\n",
    "                             layers.Dense(1,activation=\"sigmoid\")], name=\"model_pretrained\")\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=\"adam\",\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x=X_train,\n",
    "              y=y_train,\n",
    "              epochs=20,\n",
    "              validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d83f98ff-05fc-46ae-818f-80c04088f332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8070866141732284,\n",
       " 'precision': 0.8074538079268796,\n",
       " 'recall': 0.8070866141732284,\n",
       " 'f1': 0.8062397439876305}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(y_true=y_test,\n",
    "                  y_pred=tf.squeeze(tf.round(model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e8045c-ad6e-423b-b55f-542b8fa6a2d5",
   "metadata": {},
   "source": [
    "The model is able to predict the tweet class with a fairly high accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d84c3a-6e85-4632-a5f9-8ecd8da0b7ad",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34897e-b26a-44a2-992f-4370a3d5c691",
   "metadata": {},
   "source": [
    "[Kopal Garg](https://www.linkedin.com/in/gargkopal/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera747-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9be77b-d522-48fd-b7a5-f8556fae8080",
   "metadata": {},
   "source": [
    "Kopal is a Masters student in Computer Science at the University of Toronto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba7d5e-35aa-430c-bc6d-34bf2724fbe1",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b25298-af01-4db7-8d49-b7bfab9163f7",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2022-07-18|0.1|Kopal|Create Lab|\n",
    "|2022-08-30|0.1|Steve Hord|QA pass edits|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5947b-b8ac-48ca-83eb-6350140672ff",
   "metadata": {},
   "source": [
    "Copyright © 2022 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
